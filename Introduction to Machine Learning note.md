# Introduction to Machine Learning

## Week 2

### Probability Refresher

* Joint, marginal, conditional probability

  $X\in \{x+i\}$  and $Y \in \{y_i\}$ 

  $n_{i,}j = \# \{X=x_i \land y = y_j\}$

  $c_j= \# \{X=x_i\}$

  $r_j= \# \{Y=y_i\}$

  Then we can drive

  * Joint probability	 $p(X = x_i, Y=y_i)=\frac{n_{ij}}{N}$
  * Marginal probability     $p(X=x_i)=\frac{c_i}{N}$
  * Conditional probability    $p(Y= y_i|X=x_i)=\frac{n_{ij}}{c_i}$ 

* Continuous Variables

* Gaussian distribution

  * 1-D case
    * Mean $\mu$
    * Variance $\sigma^2$
  * Multi-dimensional case
    * Mean $\mu$
    * Covariance $\sum$

* Likehood of $\theta$

  **TBC**

  * Computation of the likehood

    Single data point: $p(x|\theta)$

    Assumption: all data points are independent :

    **TBC**

  * Estimation of the likehood $\theta$

    **TBC**

